{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# NCS Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Â© 2020 Nokia\n",
    "\n",
    "Licensed under the BSD 3 Clause license\n",
    "\n",
    "SPDX-License-Identifier: BSD-3-Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "timeout = 3600 * 10 # 10 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"snippets_collection\"] = \"so-ds-feb20\"\n",
    "os.environ[\"train_snippets_collection\"] = \"so-ds-feb20\"\n",
    "os.environ[\"valid_dataset\"] = \"so-ds-feb20-valid\"\n",
    "os.environ[\"test_dataset\"] = \"so-ds-feb20-test\"\n",
    "output_dir = Path(\"so-ds-feb20\")\n",
    "\n",
    "os.environ[\"snippets_collection\"] = \"conala-curated\"\n",
    "os.environ[\"train_snippets_collection\"] = \"conala-curated\"\n",
    "os.environ[\"valid_dataset\"] = \"conala-curated-0.5-test\"\n",
    "os.environ[\"test_dataset\"] = \"conala-curated-0.5-test\"\n",
    "output_dir = Path(\"conala\")\n",
    "\n",
    "os.environ[\"snippets_collection\"] = \"staqc-py-cleaned\"\n",
    "os.environ[\"train_snippets_collection\"] = \"staqc-py-cleaned\"\n",
    "os.environ[\"valid_dataset\"] = \"staqc-py-raw-valid\"\n",
    "os.environ[\"test_dataset\"] = \"staqc-py-raw-test\"\n",
    "output_dir = Path(\"staqc-py\")\n",
    "\n",
    "os.environ[\"output_dir\"] = str(output_dir)\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocessing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides_ = [{}, {\"lemmatize\": False}, {\"remove_stop\": False}] + 8 * [{}]\n",
    "code_overrides_ = [{},\n",
    "                  {\"lemmatize\": False}, \n",
    "                  {\"remove_stop\": False}, \n",
    "                  {\"keep_comments\": False},\n",
    "                  {\"identifier_types\": [\"call\", \"import\"]}, # without other identifiers                   \n",
    "                  {\"identifier_types\": [ \"attribute\", \"argument\", \"keyword_argument\", \"generic\", \"import\"]}, # without calls\n",
    "                  {\"identifier_types\": [ \"attribute\", \"argument\", \"keyword_argument\", \"generic\", \"call\"]},   # without import\n",
    "                  {\"rstrip_numbers\": False},\n",
    "                  {\"keep_loops\": False},\n",
    "                  {\"keep_bin_ops\": False},\n",
    "                  {\"case_split\": False},\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"fast_text_overrides\"] = \"{}\"\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "for i, (text_overrides, code_overrides) in enumerate(zip(text_overrides_, code_overrides_)):\n",
    "    os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "    os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "    output_base = str(output_dir/f\"ncs_preprocess_{i}\")\n",
    "    !python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,  \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False, \"identifier_types\": [\"call\", \"import\"]}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "output_base = str(output_dir/f\"original_ncs\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs + variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,  \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({})\n",
    "\n",
    "output_base = str(output_dir/f\"original_ncs+varnames\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs + zip fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,   \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False,\"identifier_types\": [\"call\", \"import\"]}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({})\n",
    "\n",
    "\n",
    "output_base = str(output_dir/f\"original_ncs+zipfn\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs + epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,  \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False, \"identifier_types\": [\"call\", \"import\"]}\n",
    "fasttext_overrides = {\"epoch\": 30}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps(fasttext_overrides)\n",
    "output_base = str(output_dir/f\"original_ncs+epochs\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs + window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,  \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False, \"identifier_types\": [\"call\", \"import\"]}\n",
    "fasttext_overrides = {\"ws\": 20}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps(fasttext_overrides)\n",
    "output_base = str(output_dir/f\"original_ncs+ws\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Original ncs + minCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,   \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False, \"identifier_types\": [\"call\", \"import\"]}\n",
    "fasttext_overrides = {\"minCount\": 1}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps(fasttext_overrides)\n",
    "output_base = str(output_dir/f\"original_ncs+mincount\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Original ncs + minCount + epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text_overrides = {\"lemmatize\": False}\n",
    "code_overrides = {\"lemmatize\": False,   \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False, \"identifier_types\": [\"call\", \"import\"]}\n",
    "fasttext_overrides = {\"minCount\": 1, \"epoch\": 30}\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "\n",
    "os.environ[\"text_overrides\"] = json.dumps(text_overrides)\n",
    "os.environ[\"code_overrides\"] = json.dumps(code_overrides)\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps(fasttext_overrides)\n",
    "output_base = str(output_dir/f\"original_ncs+mincount\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Fasttext hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Fasttext 1 (initial exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = \"{}\"\n",
    "os.environ[\"code_overrides\"] = \"{}\"\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "fast_text_overrides_ = [{\"ws\": 10}, {\"ws\": 20}, {\"ws\": 30}, {\"dim\": 50}, {\"epoch\": 10}, {\"neg\": 10}, {\"t\": 0.01},{\"t\": 0.001}, {\"t\": 0.00001}]\n",
    "\n",
    "for i, fast_text_overrides in enumerate(fast_text_overrides_):\n",
    "    os.environ[\"fast_text_overrides\"] = json.dumps(fast_text_overrides)\n",
    "    output_base = str(output_dir/f\"fasttext_{i}\")\n",
    "    !python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Increasing window size helps\n",
    "- Increasing the number of epochs helps\n",
    "- Increasing the number of negative samples helps\n",
    "- Lowering the sampling threshold does not help\n",
    "- Decreasing the embedding dimensionality does not help\n",
    "\n",
    "Window size, number of epochs, and negative samples all increase the number of times an embedding is updated. The next step is to tune the number of epochs and then check if increasing the window and number of negative samples still helps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Fasttext 2: epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = \"{}\"\n",
    "os.environ[\"code_overrides\"] = \"{}\"\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "fast_text_overrides_ = [{\"epoch\": 15}, {\"epoch\": 20}, {\"epoch\": 25}, {\"epoch\": 30}, {\"epoch\": 40}, {\"epoch\": 50}]\n",
    "\n",
    "for i, fast_text_overrides in enumerate(fast_text_overrides_):\n",
    "    os.environ[\"fast_text_overrides\"] = json.dumps(fast_text_overrides)\n",
    "    output_base = str(output_dir/f\"fasttext_2.{i}\")\n",
    "    !python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Observations\n",
    "\n",
    "Training for more than 30 epochs does not help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Fasttext 3: epochs and windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = \"{}\"\n",
    "os.environ[\"code_overrides\"] = \"{}\"\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "epochs = [30]\n",
    "windows = [10, 15, 20, 25, 30, 35, 40]\n",
    "fast_text_overrides_ = [{\"epoch\": epoch, \"ws\": ws} for epoch in epochs for ws in windows]\n",
    "\n",
    "for i, fast_text_overrides in enumerate(fast_text_overrides_):\n",
    "    os.environ[\"fast_text_overrides\"] = json.dumps(fast_text_overrides)\n",
    "    output_base = str(output_dir/f\"fasttext_3.{i}\")\n",
    "    !python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Observations\n",
    "\n",
    "Increasing window size still helps a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Fasttext 4: mincount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = \"{}\"\n",
    "os.environ[\"code_overrides\"] = \"{}\"\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"minCount\": 1, \"epoch\": 30, \"ws\": 20})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_end\"\n",
    "output_base = str(output_dir/f\"fasttext_4\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Zip function \n",
    "(How you combine code tokens and description tokens to a single fasttext *sentence/context*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = \"{}\"\n",
    "os.environ[\"code_overrides\"] = \"{}\"\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"ws\": 20, \"minCount\": 1})\n",
    "\n",
    "zip_fns = [\"zip_descr_start_end\", \"zip_descr_middle_and_start_end\", \"zip_descr_middle\", \"zip_descr_end\"]\n",
    "\n",
    "for i, zip_fn in enumerate(zip_fns):\n",
    "    os.environ[\"zip_fn\"] = zip_fn\n",
    "    output_base = str(output_dir/f\"zip_fn.{i}\")\n",
    "    !python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Save best NCS hyperparam configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ncs.ipynb to html\n",
      "[NbConvertApp] Executing notebook with kernel: codesearch_ml4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False})\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"ws\": 20, \"dim\":100, \"minCount\": 1})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "os.environ[\"model_filename\"] = str(output_dir/\"best_ncs_embedder\")\n",
    "output_base = str(output_dir/f\"best\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Best NCS ablation epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False})\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"ws\": 20, \"minCount\": 1})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "#os.environ[\"model_filename\"] = \"../trained_models/ncs-embedder-so.feb20\"\n",
    "output_base = str(output_dir/f\"best-epoch\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Best NCS ablation variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False,\"identifier_types\": [\"call\", \"import\"] })\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"ws\": 20, \"minCount\": 1})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "#os.environ[\"model_filename\"] = \"../trained_models/ncs-embedder-so.feb20\"\n",
    "output_base = str(output_dir/f\"best-variables\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Best NCS ablation zip fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False})\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"ws\": 20, \"minCount\": 1})\n",
    "os.environ.pop(\"zip_fn\", None)\n",
    "#os.environ[\"model_filename\"] = \"../trained_models/ncs-embedder-so.feb20\"\n",
    "output_base = str(output_dir/f\"best-zip\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Best NCS ablation window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False})\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"minCount\": 1})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "#os.environ[\"model_filename\"] = \"../trained_models/ncs-embedder-so.feb20\"\n",
    "output_base = str(output_dir/f\"best-ws\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Best NCS ablation minCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ncs.ipynb to html\n",
      "[NbConvertApp] Executing notebook with kernel: codesearch_ml4\n",
      "Read 87M words\n",
      "Number of words:  167684\n",
      "Number of labels: 0\n",
      "Progress:  23.9% words/sec/thread:   15705 lr:  0.038067 avg.loss:  0.335618 ETA:   1h49m 0s avg.loss:  0.609477 ETA:   2h24m52s29s words/sec/thread:   15703 lr:  0.049665 avg.loss:  0.591211 ETA:   2h22m14s22m10sh22m11s 0.049470 avg.loss:  0.598263 ETA:   2h21m48s avg.loss:  0.593532 ETA:   2h21m26s30s21m29s words/sec/thread:   15656 lr:  0.049242 avg.loss:  0.591274 ETA:   2h21m26s  15640 lr:  0.049194 avg.loss:  0.593165 ETA:   2h21m27s  15631 lr:  0.049155 avg.loss:  0.590066 ETA:   2h21m24s lr:  0.048998 avg.loss:  0.589546 ETA:   2h20m56s 0.048965 avg.loss:  0.589837 ETA:   2h20m50s words/sec/thread:   15617 lr:  0.048844 avg.loss:  0.588022 ETA:   2h20m39s  15587 lr:  0.048700 avg.loss:  0.582999 ETA:   2h20m30s  15582 lr:  0.048634 avg.loss:  0.578394 ETA:   2h20m21s  2.8% words/sec/thread:   15585 lr:  0.048590 avg.loss:  0.575903 ETA:   2h20m12s words/sec/thread:   15582 lr:  0.048578 avg.loss:  0.575062 ETA:   2h20m11s  15579 lr:  0.048552 avg.loss:  0.572859 ETA:   2h20m 9s% words/sec/thread:   15573 lr:  0.048527 avg.loss:  0.571514 ETA:   2h20m 7s words/sec/thread:   15572 lr:  0.048514 avg.loss:  0.571294 ETA:   2h20m 6s  3.1% words/sec/thread:   15546 lr:  0.048437 avg.loss:  0.568537 ETA:   2h20m 7s  3.2% words/sec/thread:   15544 lr:  0.048396 avg.loss:  0.567596 ETA:   2h20m 0s words/sec/thread:   15539 lr:  0.048331 avg.loss:  0.562827 ETA:   2h19m52s  15531 lr:  0.048285 avg.loss:  0.560085 ETA:   2h19m48s  3.5% words/sec/thread:   15535 lr:  0.048227 avg.loss:  0.559957 ETA:   2h19m36s  3.6% words/sec/thread:   15533 lr:  0.048195 avg.loss:  0.560248 ETA:   2h19m32s words/sec/thread:   15538 lr:  0.048134 avg.loss:  0.559000 ETA:   2h19m18s  2h19m 7s  2h18m 9s 0.047699 avg.loss:  0.551339 ETA:   2h17m51s 0.047626 avg.loss:  0.547464 ETA:   2h17m39s  15568 lr:  0.047503 avg.loss:  0.542946 ETA:   2h17m13s 0.047342 avg.loss:  0.536387 ETA:   2h16m39s% words/sec/thread:   15585 lr:  0.047306 avg.loss:  0.535386 ETA:   2h16m30s lr:  0.047292 avg.loss:  0.534860 ETA:   2h16m26s 0.047273 avg.loss:  0.534295 ETA:   2h16m23s avg.loss:  0.532064 ETA:   2h16m10s lr:  0.047152 avg.loss:  0.530077 ETA:   2h15m57s  15596 lr:  0.047129 avg.loss:  0.529443 ETA:   2h15m53s 0.047042 avg.loss:  0.527212 ETA:   2h15m36s 0.526138 ETA:   2h15m25s  2h15m17s  15611 lr:  0.046831 avg.loss:  0.522161 ETA:   2h14m54s 0.046811 avg.loss:  0.521469 ETA:   2h14m50s words/sec/thread:   15612 lr:  0.046771 avg.loss:  0.520783 ETA:   2h14m43s% words/sec/thread:   15611 lr:  0.046746 avg.loss:  0.520446 ETA:   2h14m39s 0.046705 avg.loss:  0.519817 ETA:   2h14m32s 0.046669 avg.loss:  0.519414 ETA:   2h14m25s words/sec/thread:   15624 lr:  0.046333 avg.loss:  0.507095 ETA:   2h13m21s 0.046322 avg.loss:  0.506818 ETA:   2h13m19s 0.506154 ETA:   2h13m12s45s avg.loss:  0.503757 ETA:   2h12m40s 0.502687 ETA:   2h12m24s 0.046002 avg.loss:  0.502321 ETA:   2h12m16s avg.loss:  0.502264 ETA:   2h12m15s12s lr:  0.045869 avg.loss:  0.500535 ETA:   2h11m53s 0.500497 ETA:   2h11m50s 0.045844 avg.loss:  0.500296 ETA:   2h11m49s 0.045822 avg.loss:  0.500008 ETA:   2h11m44s  15641 lr:  0.045799 avg.loss:  0.499817 ETA:   2h11m40s 0.045767 avg.loss:  0.499393 ETA:   2h11m34s words/sec/thread:   15645 lr:  0.045725 avg.loss:  0.498688 ETA:   2h11m25s avg.loss:  0.498313 ETA:   2h11m22sh11m10s  15649 lr:  0.045616 avg.loss:  0.496128 ETA:   2h11m 5s 0.045553 avg.loss:  0.495282 ETA:   2h10m54s ETA:   2h10m53s  15648 lr:  0.045521 avg.loss:  0.495110 ETA:   2h10m49s% words/sec/thread:   15649 lr:  0.045440 avg.loss:  0.493602 ETA:   2h10m35s words/sec/thread:   15652 lr:  0.045408 avg.loss:  0.492427 ETA:   2h10m28s 0.045382 avg.loss:  0.491503 ETA:   2h10m22s  15652 lr:  0.045375 avg.loss:  0.491208 ETA:   2h10m22s  15654 lr:  0.045258 avg.loss:  0.487465 ETA:   2h10m 1s 9m54s 0.045097 avg.loss:  0.484632 ETA:   2h 9m30s lr:  0.045071 avg.loss:  0.484179 ETA:   2h 9m26s  2h 8m49s  15662 lr:  0.044845 avg.loss:  0.480454 ETA:   2h 8m46s ETA:   2h 8m42s  15663 lr:  0.044807 avg.loss:  0.480410 ETA:   2h 8m38s  15664 lr:  0.044731 avg.loss:  0.477892 ETA:   2h 8m25s words/sec/thread:   15663 lr:  0.044724 avg.loss:  0.477504 ETA:   2h 8m24s% words/sec/thread:   15662 lr:  0.044696 avg.loss:  0.476225 ETA:   2h 8m20s 0.473295 ETA:   2h 8m 7s  15665 lr:  0.044574 avg.loss:  0.470953 ETA:   2h 7m57s lr:  0.044521 avg.loss:  0.468618 ETA:   2h 7m47s avg.loss:  0.468273 ETA:   2h 7m46s words/sec/thread:   15666 lr:  0.044475 avg.loss:  0.466588 ETA:   2h 7m40s 0.466283 ETA:   2h 7m38s 0.465840 ETA:   2h 7m36s words/sec/thread:   15670 lr:  0.044379 avg.loss:  0.462654 ETA:   2h 7m21s avg.loss:  0.461164 ETA:   2h 7m14s  15673 lr:  0.044300 avg.loss:  0.459960 ETA:   2h 7m 6s lr:  0.044294 avg.loss:  0.459710 ETA:   2h 7m 5s words/sec/thread:   15673 lr:  0.044212 avg.loss:  0.456180 ETA:   2h 6m51s 0.044160 avg.loss:  0.454043 ETA:   2h 6m43s avg.loss:  0.452453 ETA:   2h 6m34s lr:  0.044087 avg.loss:  0.451816 ETA:   2h 6m30s lr:  0.044021 avg.loss:  0.449404 ETA:   2h 6m18s 0.044014 avg.loss:  0.449174 ETA:   2h 6m17s 0.043983 avg.loss:  0.448126 ETA:   2h 6m11s  15676 lr:  0.043947 avg.loss:  0.446862 ETA:   2h 6m 4s  15676 lr:  0.043908 avg.loss:  0.445536 ETA:   2h 5m57s words/sec/thread:   15675 lr:  0.043901 avg.loss:  0.445236 ETA:   2h 5m57s 0.043861 avg.loss:  0.443311 ETA:   2h 5m51s lr:  0.043854 avg.loss:  0.443048 ETA:   2h 5m49s  15674 lr:  0.043848 avg.loss:  0.442879 ETA:   2h 5m48s 0.043810 avg.loss:  0.441757 ETA:   2h 5m41s 0.043796 avg.loss:  0.441293 ETA:   2h 5m38s 0.043779 avg.loss:  0.440790 ETA:   2h 5m36s lr:  0.043756 avg.loss:  0.440027 ETA:   2h 5m31s  2h 5m29s 0.043733 avg.loss:  0.439458 ETA:   2h 5m27s 0.043690 avg.loss:  0.438066 ETA:   2h 5m19s 0.043604 avg.loss:  0.435639 ETA:   2h 5m 4s  15682 lr:  0.043505 avg.loss:  0.432948 ETA:   2h 4m45s words/sec/thread:   15683 lr:  0.043469 avg.loss:  0.431862 ETA:   2h 4m38s words/sec/thread:   15683 lr:  0.043454 avg.loss:  0.431488 ETA:   2h 4m36s 0.043285 avg.loss:  0.426518 ETA:   2h 4m 8s ETA:   2h 4m 7s 13.5% words/sec/thread:   15681 lr:  0.043252 avg.loss:  0.425606 ETA:   2h 4m 2s 0.043156 avg.loss:  0.422708 ETA:   2h 3m46s 0.420932 ETA:   2h 3m35s 0.043066 avg.loss:  0.419936 ETA:   2h 3m30s avg.loss:  0.417783 ETA:   2h 3m18s  15684 lr:  0.042951 avg.loss:  0.416376 ETA:   2h 3m 9s  15685 lr:  0.042943 avg.loss:  0.416138 ETA:   2h 3m 7s  15684 lr:  0.042928 avg.loss:  0.415654 ETA:   2h 3m 5s ETA:   2h 2m54s ETA:   2h 2m53s49s46s lr:  0.042756 avg.loss:  0.411014 ETA:   2h 2m35s lr:  0.042741 avg.loss:  0.410609 ETA:   2h 2m32s 0.042641 avg.loss:  0.408004 ETA:   2h 2m14s 0.042625 avg.loss:  0.407644 ETA:   2h 2m11s 0.407130 ETA:   2h 2m 6s avg.loss:  0.406753 ETA:   2h 2m 2s lr:  0.042535 avg.loss:  0.405978 ETA:   2h 1m55s lr:  0.042521 avg.loss:  0.405672 ETA:   2h 1m53s  15688 lr:  0.042508 avg.loss:  0.405427 ETA:   2h 1m51s 0.042496 avg.loss:  0.405222 ETA:   2h 1m49s lr:  0.042469 avg.loss:  0.404670 ETA:   2h 1m44s 0.042444 avg.loss:  0.404082 ETA:   2h 1m40s lr:  0.042420 avg.loss:  0.403551 ETA:   2h 1m36s avg.loss:  0.402777 ETA:   2h 1m32s avg.loss:  0.402560 ETA:   2h 1m30s 0.042341 avg.loss:  0.401677 ETA:   2h 1m23s 0.400743 ETA:   2h 1m16s ETA:   2h 1m 7s 0.399221 ETA:   2h 1m 3s 0.042168 avg.loss:  0.397641 ETA:   2h 0m52s lr:  0.042136 avg.loss:  0.396870 ETA:   2h 0m46s 0.042110 avg.loss:  0.396256 ETA:   2h 0m42s lr:  0.042104 avg.loss:  0.396121 ETA:   2h 0m41s lr:  0.042069 avg.loss:  0.395424 ETA:   2h 0m34s ETA:   2h 0m24s ETA:   2h 0m20s 0.041962 avg.loss:  0.393062 ETA:   2h 0m16s 0.041954 avg.loss:  0.392908 ETA:   2h 0m14s avg.loss:  0.391610 ETA:   2h 0m 4s  2h 0m 0s ETA:   1h59m59s avg.loss:  0.390681 ETA:   1h59m55s 0.041801 avg.loss:  0.389913 ETA:   1h59m47s 0.041735 avg.loss:  0.388602 ETA:   1h59m36s  15692 lr:  0.041729 avg.loss:  0.388473 ETA:   1h59m35s 0.041722 avg.loss:  0.388345 ETA:   1h59m34s lr:  0.041693 avg.loss:  0.387714 ETA:   1h59m29s lr:  0.041661 avg.loss:  0.387268 ETA:   1h59m23s21s 0.041639 avg.loss:  0.386924 ETA:   1h59m20s 0.386595 ETA:   1h59m17s lr:  0.041616 avg.loss:  0.386456 ETA:   1h59m16s avg.loss:  0.386216 ETA:   1h59m14s  15691 lr:  0.041599 avg.loss:  0.386134 ETA:   1h59m13s  1h59m11s lr:  0.041418 avg.loss:  0.382523 ETA:   1h58m41s ETA:   1h58m35s lr:  0.041354 avg.loss:  0.381324 ETA:   1h58m29s lr:  0.041348 avg.loss:  0.381215 ETA:   1h58m28s lr:  0.041317 avg.loss:  0.380648 ETA:   1h58m23s 0.041311 avg.loss:  0.380537 ETA:   1h58m22s words/sec/thread:   15693 lr:  0.041263 avg.loss:  0.379482 ETA:   1h58m14s  15693 lr:  0.041246 avg.loss:  0.379115 ETA:   1h58m11s lr:  0.041234 avg.loss:  0.378900 ETA:   1h58m 9s  15694 lr:  0.041223 avg.loss:  0.378714 ETA:   1h58m 7s  15694 lr:  0.041185 avg.loss:  0.378078 ETA:   1h58m 1s 0.041140 avg.loss:  0.377266 ETA:   1h57m52s  15694 lr:  0.041130 avg.loss:  0.377081 ETA:   1h57m51s words/sec/thread:   15694 lr:  0.041124 avg.loss:  0.376963 ETA:   1h57m50s 0.041088 avg.loss:  0.376279 ETA:   1h57m43s 0.375724 ETA:   1h57m37s 0.040975 avg.loss:  0.374326 ETA:   1h57m24s 0.040898 avg.loss:  0.372872 ETA:   1h57m10s words/sec/thread:   15696 lr:  0.040879 avg.loss:  0.372546 ETA:   1h57m 7s  15695 lr:  0.040853 avg.loss:  0.372119 ETA:   1h57m 3s 0.040834 avg.loss:  0.371791 ETA:   1h57m 0s  1h56m58s  15695 lr:  0.040807 avg.loss:  0.371374 ETA:   1h56m55s 0.040794 avg.loss:  0.371215 ETA:   1h56m53s  1h56m51s avg.loss:  0.370997 ETA:   1h56m50s avg.loss:  0.370585 ETA:   1h56m46s44s37s 0.369134 ETA:   1h56m31s  15697 lr:  0.040600 avg.loss:  0.368150 ETA:   1h56m18s lr:  0.040584 avg.loss:  0.367908 ETA:   1h56m15s  15698 lr:  0.040563 avg.loss:  0.367652 ETA:   1h56m12ssss 0.040530 avg.loss:  0.366930 ETA:   1h56m 6s 0.040478 avg.loss:  0.366074 ETA:   1h55m57s  1h55m54s  1h55m47s55m45s 0.040388 avg.loss:  0.364472 ETA:   1h55m42s  1h55m33s  1h55m32s 0.040312 avg.loss:  0.363080 ETA:   1h55m29s avg.loss:  0.362873 ETA:   1h55m26s25s 0.040237 avg.loss:  0.362156 ETA:   1h55m15s14s11s 0.361296 ETA:   1h55m 2s ETA:   1h54m55s 0.360395 ETA:   1h54m49s 0.040078 avg.loss:  0.360348 ETA:   1h54m48s43s39s 0.039992 avg.loss:  0.359265 ETA:   1h54m33s 0.039958 avg.loss:  0.358779 ETA:   1h54m27s lr:  0.039886 avg.loss:  0.357501 ETA:   1h54m15s lr:  0.039811 avg.loss:  0.356387 ETA:   1h54m 1s avg.loss:  0.356311 ETA:   1h54m 0s  1h53m52s 0.039728 avg.loss:  0.355236 ETA:   1h53m47s  15701 lr:  0.039723 avg.loss:  0.355185 ETA:   1h53m46s lr:  0.039714 avg.loss:  0.355060 ETA:   1h53m44s 0.039709 avg.loss:  0.355007 ETA:   1h53m44s words/sec/thread:   15701 lr:  0.039694 avg.loss:  0.354868 ETA:   1h53m41s  15702 lr:  0.039655 avg.loss:  0.354466 ETA:   1h53m34s 0.039642 avg.loss:  0.354283 ETA:   1h53m32s lr:  0.039627 avg.loss:  0.354107 ETA:   1h53m29s 0.039610 avg.loss:  0.353864 ETA:   1h53m27s words/sec/thread:   15701 lr:  0.039589 avg.loss:  0.353599 ETA:   1h53m23s  15700 lr:  0.039572 avg.loss:  0.353461 ETA:   1h53m21s 0.039567 avg.loss:  0.353400 ETA:   1h53m20ss ETA:   1h53m12s  15701 lr:  0.039471 avg.loss:  0.352044 ETA:   1h53m 3s lr:  0.039465 avg.loss:  0.351980 ETA:   1h53m 2s lr:  0.039454 avg.loss:  0.351803 ETA:   1h53m 0s 0.039448 avg.loss:  0.351731 ETA:   1h52m59s 0.039444 avg.loss:  0.351674 ETA:   1h52m58s lr:  0.039437 avg.loss:  0.351576 ETA:   1h52m57s 0.039432 avg.loss:  0.351508 ETA:   1h52m56s avg.loss:  0.350618 ETA:   1h52m45s 0.350516 ETA:   1h52m44s 0.039301 avg.loss:  0.349015 ETA:   1h52m33s lr:  0.039294 avg.loss:  0.348862 ETA:   1h52m32s 0.039249 avg.loss:  0.348223 ETA:   1h52m24s lr:  0.039220 avg.loss:  0.347809 ETA:   1h52m19s 0.039130 avg.loss:  0.346709 ETA:   1h52m 4s% words/sec/thread:   15702 lr:  0.039117 avg.loss:  0.346552 ETA:   1h52m 1s lr:  0.039104 avg.loss:  0.346349 ETA:   1h51m59s  15702 lr:  0.039037 avg.loss:  0.345531 ETA:   1h51m48s 0.039027 avg.loss:  0.345395 ETA:   1h51m46s 0.039019 avg.loss:  0.345321 ETA:   1h51m45s avg.loss:  0.345137 ETA:   1h51m42s  1h51m40s 0.344902 ETA:   1h51m36s 0.038956 avg.loss:  0.344702 ETA:   1h51m33s lr:  0.038921 avg.loss:  0.344323 ETA:   1h51m27s 0.038878 avg.loss:  0.343854 ETA:   1h51m20s 0.343565 ETA:   1h51m16s avg.loss:  0.343348 ETA:   1h51m12s avg.loss:  0.343283 ETA:   1h51m11s avg.loss:  0.343005 ETA:   1h51m 6s  15704 lr:  0.038787 avg.loss:  0.342884 ETA:   1h51m 4s 0.342839 ETA:   1h51m 3s 0.342544 ETA:   1h50m59s lr:  0.038722 avg.loss:  0.342149 ETA:   1h50m53s  1h50m50s 0.038702 avg.loss:  0.341905 ETA:   1h50m49s 0.038690 avg.loss:  0.341773 ETA:   1h50m47s 0.038667 avg.loss:  0.341549 ETA:   1h50m44s  15703 lr:  0.038627 avg.loss:  0.341026 ETA:   1h50m37s 0.038596 avg.loss:  0.340615 ETA:   1h50m32s 0.038579 avg.loss:  0.340445 ETA:   1h50m29s 0.339928 ETA:   1h50m20s 0.038479 avg.loss:  0.339434 ETA:   1h50m11s  15704 lr:  0.038460 avg.loss:  0.339289 ETA:   1h50m 8s 0.339235 ETA:   1h50m 7s 0.038449 avg.loss:  0.339163 ETA:   1h50m 6s lr:  0.038436 avg.loss:  0.338990 ETA:   1h50m 4s 0.038431 avg.loss:  0.338956 ETA:   1h50m 3s lr:  0.038414 avg.loss:  0.338810 ETA:   1h50m 0s 0.038408 avg.loss:  0.338767 ETA:   1h49m59s 0.038373 avg.loss:  0.338386 ETA:   1h49m53s avg.loss:  0.338225 ETA:   1h49m49s 0.038207 avg.loss:  0.336923 ETA:   1h49m24s 0.336488 ETA:   1h49m16s lr:  0.038129 avg.loss:  0.336211 ETA:   1h49m10s lr:  0.038106 avg.loss:  0.335932 ETA:   1h49m 6s  15706 lr:  0.038100 avg.loss:  0.335898 ETA:   1h49m 5s 0.038094 avg.loss:  0.335854 ETA:   1h49m 4s lr:  0.038089 avg.loss:  0.335799 ETA:   1h49m 3s 0.038079 avg.loss:  0.335729 ETA:   1h49m 2s"
     ]
    }
   ],
   "source": [
    "os.environ[\"text_overrides\"] = json.dumps({\"lemmatize\": False})\n",
    "os.environ[\"code_overrides\"] = json.dumps({\"lemmatize\":False, \"keep_loops\": False, \"keep_bin_ops\": False, \"rstrip_numbers\": False})\n",
    "os.environ[\"fast_text_overrides\"] = json.dumps({\"epoch\": 30, \"ws\": 20})\n",
    "os.environ[\"zip_fn\"] = \"zip_descr_middle_and_start_end\"\n",
    "#os.environ[\"model_filename\"] = \"../trained_models/ncs-embedder-so.feb20\"\n",
    "output_base = str(output_dir/f\"best-mincount\")\n",
    "!python -m nbconvert ncs.ipynb --execute --NbConvertApp.output_base=$output_base --ExecutePreprocessor.timeout=$timeout  \n",
    "\n",
    "os.environ[\"model_filename\"] = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
