{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© 2020 Nokia\n",
    "\n",
    "Licensed under the BSD 3 Clause license\n",
    "\n",
    "SPDX-License-Identifier: BSD-3-Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare StaQC\n",
    "\n",
    "This notebook contains the code to create a snippet collection from the original StaQC dataset:\n",
    "- We convert the original pickle files in a jsonl format consistent with the codesearch library. \n",
    "- We filter out code snippets that can not be parsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we convert the Python 2 pickle files to a jsonl file\n",
    "Note that this part requires a python 2 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "import cPickle as pickle\n",
    "import traceback\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Warning: Failed to set locale category LC_NUMERIC to en_BE.\nWarning: Failed to set locale category LC_TIME to en_BE.\nWarning: Failed to set locale category LC_COLLATE to en_BE.\nWarning: Failed to set locale category LC_MONETARY to en_BE.\nWarning: Failed to set locale category LC_MESSAGES to en_BE.\nFile ‘python_how_to_do_it_by_classifier_multiple_qid_to_title.pickle’ already there; not retrieving.\n\nWarning: Failed to set locale category LC_NUMERIC to en_BE.\nWarning: Failed to set locale category LC_TIME to en_BE.\nWarning: Failed to set locale category LC_COLLATE to en_BE.\nWarning: Failed to set locale category LC_MONETARY to en_BE.\nWarning: Failed to set locale category LC_MESSAGES to en_BE.\nFile ‘python_how_to_do_it_qid_by_classifier_unlabeled_single_code_answer_qid_to_code.pickle’ already there; not retrieving.\n\nWarning: Failed to set locale category LC_NUMERIC to en_BE.\nWarning: Failed to set locale category LC_TIME to en_BE.\nWarning: Failed to set locale category LC_COLLATE to en_BE.\nWarning: Failed to set locale category LC_MONETARY to en_BE.\nWarning: Failed to set locale category LC_MESSAGES to en_BE.\nFile ‘python_how_to_do_it_qid_by_classifier_unlabeled_single_code_answer_qid_to_title.pickle’ already there; not retrieving.\n\nWarning: Failed to set locale category LC_NUMERIC to en_BE.\nWarning: Failed to set locale category LC_TIME to en_BE.\nWarning: Failed to set locale category LC_COLLATE to en_BE.\nWarning: Failed to set locale category LC_MONETARY to en_BE.\nWarning: Failed to set locale category LC_MESSAGES to en_BE.\nFile ‘python_how_to_do_it_by_classifier_multiple_iid_to_code.pickle’ already there; not retrieving.\n\n"
    }
   ],
   "source": [
    "DATASET_URLS = {\n",
    "    \"python-multi-code\": 'https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset/raw/master/annotation_tool/data/code_solution_labeled_data/source/python_how_to_do_it_by_classifier_multiple_iid_to_code.pickle',\n",
    "    \"python-multi-descr\": \"https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset/raw/master/annotation_tool/data/code_solution_labeled_data/source/python_how_to_do_it_by_classifier_multiple_qid_to_title.pickle\",\n",
    "    \"python-single-code\": \"https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset/raw/master/annotation_tool/data/code_solution_labeled_data/source/python_how_to_do_it_qid_by_classifier_unlabeled_single_code_answer_qid_to_code.pickle\",\n",
    "    \"python-single-descr\": 'https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset/raw/master/annotation_tool/data/code_solution_labeled_data/source/python_how_to_do_it_qid_by_classifier_unlabeled_single_code_answer_qid_to_title.pickle'\n",
    "}\n",
    "\n",
    "\n",
    "def pickle_filename(url):\n",
    "    return ntpath.basename(url)\n",
    "\n",
    "def load_pickle(url):\n",
    "    with open(pickle_filename(url), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for dataset, url in DATASET_URLS.items():\n",
    "    !wget -nc $url\n",
    "    datasets[dataset] = load_pickle(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2snippets = defaultdict(list)\n",
    "\n",
    "description_ds = dict(datasets[\"python-multi-descr\"])\n",
    "description_ds.update(datasets[\"python-single-descr\"])\n",
    "\n",
    "records = []\n",
    "for snippet_dsname in [\"python-multi-code\", \"python-single-code\"]:\n",
    "    snippet_ds = datasets[snippet_dsname]\n",
    "    for full_id, code in snippet_ds.items():\n",
    "        if isinstance(full_id, tuple):\n",
    "            so_id = full_id[0]  \n",
    "            snippet_id = \"%i_%i\" % full_id\n",
    "        else:\n",
    "            so_id = full_id\n",
    "            snippet_id = str(full_id)\n",
    "        description = description_ds[so_id]\n",
    "        attribution = \"https://stackoverflow.com/questions/%i\" % so_id\n",
    "        record = {\"rawDescription\": description, \n",
    "                  \"code\": code, \n",
    "                  \"attribution\": attribution,\n",
    "                  \"language\": \"python\",\n",
    "                  \"id\": snippet_id\n",
    "                }\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'attribution': 'https://stackoverflow.com/questions/22850218',\n  'code': u'words = set(message.split(\" \"))\\nresult = [int(word in words) for word in terms]\\n',\n  'id': '22850218',\n  'language': 'python',\n  'rawDescription': u'Create Array of found words in Python'},\n {'attribution': 'https://stackoverflow.com/questions/7602174',\n  'code': u'sort input-file.txt | uniq -u -w 3\\n',\n  'id': '7602174',\n  'language': 'python',\n  'rawDescription': u'How to only print lines with unique fields?'},\n {'attribution': 'https://stackoverflow.com/questions/10048853',\n  'code': u'from Tkinter import *\\n\\nclass MyDialog:\\n\\n    def __init__(self, parent):\\n\\n        top = self.top = Toplevel(parent)\\n\\n        Label(top, text=\"Value\").pack()\\n\\n        self.e = Entry(top)\\n        self.e.pack(padx=5)\\n\\n        b = Button(top, text=\"OK\", command=self.ok)\\n        b.pack(pady=5)\\n\\n    def ok(self):\\n\\n        print \"value is\", self.e.get()\\n\\n        self.top.destroy()\\n\\n\\nroot = Tk()\\nButton(root, text=\"Hello!\").pack()\\nroot.update()\\n\\nd = MyDialog(root)\\n\\nroot.wait_window(d.top)\\nroot.mainloop()\\n',\n  'id': '10048853',\n  'language': 'python',\n  'rawDescription': u'Input popup window for input into interactive python game'}]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "records[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "staqc_raw = \"staqc-py-raw.jsonl\"\n",
    "\n",
    "with open(staqc_raw, \"wb\") as f:\n",
    "    for r in records:\n",
    "        r = json.dumps(r)\n",
    "        f.write(r)\n",
    "        f.write(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will clean the code snippets and filter out unparseable code\n",
    "\n",
    "We check if code is parseable in two steps. First, check which snippets parse in python3. Next, we use a python2 kernel to check if the unparseable snippets do parse in python2. We take the union of the snippets that parse in python2 and python3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def maybe_clean_prompt(code):\n",
    "    prompt_patterns = r\"^(>>+[ ])|(\\.\\.\\.[ :])|(In[ ]?\\[[0-9 ]*\\]:[ ])\"\n",
    "    m = re.match(prompt_patterns, code)\n",
    "    if m:\n",
    "        lines = []\n",
    "        for l in code.split(\"\\n\"):\n",
    "            m = re.match(prompt_patterns, l)\n",
    "            if not m: continue\n",
    "            prefix = m.group()\n",
    "            lines.append(l[len(prefix):])\n",
    "        code = \"\\n\".join(lines)\n",
    "        return True, code\n",
    "    return False, code\n",
    "\n",
    "\n",
    "def split_parseable(snippets):\n",
    "    parseable = []\n",
    "    unparseable = []\n",
    "    for s in snippets:\n",
    "        code = s[\"code\"]\n",
    "        cleaned, code = maybe_clean_prompt(code)\n",
    "        s[\"code\"] = code\n",
    "        try:\n",
    "            ast.parse(code)\n",
    "            parseable.append(s)\n",
    "        except:\n",
    "            unparseable.append(s)\n",
    "    return parseable, unparseable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'code': \">>> [l[i:i+2] for i in range(0, len(l), 2)]\\n[['verb', \\n  '\\\\n\\\\n1. reading, blah, blah (to read a book with the intent of learning)\\\\n2. blah blah blah (second definition of study)\\\\n\\\\n'], \\n ['noun', \\n  '\\\\n\\\\n1. blah blah blah (the object of ones study)\\\\n2. yadda yadda yadda (second definition of study)']]\\n\\n>>> l = [l[i:i+2] for i in range(0, len(l), 2)]\\n\", 'attribution': 'https://stackoverflow.com/questions/34134408', 'language': 'python', 'rawDescription': 'how to make regex go line by line to match two strings at the same time?', 'id': '34134408_1'}\nMake regex go line by line to match two strings at the same time\n[l[i:i+2] for i in range(0, len(l), 2)]\nl = [l[i:i+2] for i in range(0, len(l), 2)]\n{'code': 'In [14]: df.reindex([\"Z\", \"C\", \"A\"])\\nOut[14]:\\ncompany  Amazon  Apple  Yahoo\\nZ             0      0    150\\nC           173      0      0\\nA             0    130      0\\n', 'attribution': 'https://stackoverflow.com/questions/30009948', 'language': 'python', 'rawDescription': 'How to reorder indexed rows based on a list in Pandas data frame', 'id': '30009948_0'}\nReorder indexed rows based on a list in Pandas data frame\ndf.reindex([\"Z\", \"C\", \"A\"])\n{'code': '>>> numpy.isnan(a)\\narray([[[False, False, False],\\n        [False, False, False],\\n        [False, False, False]],\\n\\n       [[ True,  True,  True],\\n        [False, False, False],\\n        [False, False, False]],\\n\\n       [[False, False, False],\\n        [False, False, False],\\n        [False, False, False]]], dtype=bool)\\n', 'attribution': 'https://stackoverflow.com/questions/21307420', 'language': 'python', 'rawDescription': 'How to iterate a 3D numpy array', 'id': '21307420_1'}\nIterate a 3D numpy array\nnumpy.isnan(a)\n{'code': '>>> L = \"\"\"hello\\n...\\n... - x1\\n... - x2\\n... - x3\\n...\\n... - x4\\n...\\n... - x6\\n... morning\\n... - x7\\n...\\n... world\"\"\".splitlines()\\n>>> print getblocks(L)\\n[[\\'x1\\', \\'x2\\', \\'x3\\'], [\\'x4\\']]\\n', 'attribution': 'https://stackoverflow.com/questions/2720022', 'language': 'python', 'rawDescription': 'multi-line pattern matching in python', 'id': '2720022_2'}\nMulti-line pattern matching in python\nL = \"\"\"hello\n- x1\n- x2\n- x3\n- x4\n- x6\nmorning\n- x7\nworld\"\"\".splitlines()\nprint getblocks(L)\n{'code': 'In [202]: (df.assign(bin=(pd.cut(df.loc_x, np.arange(-500, 500, xstep)).astype(str)\\n   .....:                 +\\n   .....:                 pd.cut(df.loc_y, np.arange(-500, 500, ystep)).astype(str)\\n   .....:                )\\n   .....:           )\\n   .....: )\\nOut[202]:\\n   loc_x  loc_y                       bin\\n0    -15     25         (-20, -10](0, 50]\\n1     30     35           (20, 30](0, 50]\\n2      5    -45           (0, 10](-50, 0]\\n3   -135   -200  (-140, -130](-250, -200]\\n4      5     25            (0, 10](0, 50]\\n\\nIn [203]: df_loc.sum(axis=1)\\nOut[203]:\\n0         (-20, -10](0, 50]\\n1    (-140, -130](100, 150]\\n2           (0, 10](-50, 0]\\ndtype: object\\n', 'attribution': 'https://stackoverflow.com/questions/37125507', 'language': 'python', 'rawDescription': 'Are values in one dataframe in bins of another dataframe?', 'id': '37125507_1'}\nAre values in one dataframe in bins of another dataframe\n(df.assign(bin=(pd.cut(df.loc_x, np.arange(-500, 500, xstep)).astype(str)\ndf_loc.sum(axis=1)\n{'code': 'In [11]: nested = [L[i : i+size] for i in xrange(0, len(L), size)]\\n\\nIn [12]: for sub in nested: print sub\\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\\n[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\\n[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\\n[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\\n[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\\n[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]\\n[120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]\\n[140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\\n[160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\\n[180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\\n[200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219]\\n[220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\\n[240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259]\\n[260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\\n[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]\\n[300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319]\\n[320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339]\\n[340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359]\\n[360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379]\\n[380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]\\n', 'attribution': 'https://stackoverflow.com/questions/19917173', 'language': 'python', 'rawDescription': 'divide the list into rows (create a nested list from a list)', 'id': '19917173_2'}\nDivide the list into rows (create a nested list from a list)\nnested = [L[i : i+size] for i in xrange(0, len(L), size)]\nfor sub in nested: print sub\n{'code': \">>> foo = [['one', 1], ['two', 1], ['three', 1]]\\n>>> bar = [['three', 1], ['four', 1], ['five', 1]]\\n>>> from collections import Counter\\n>>> from collections import OrderedDict\\n>>> from itertools import chain\\n>>> L = [foo, bar]\\n>>> counter = Counter()\\n>>> for item in L:\\n...     counter.update(dict(item))\\n... \\n>>> order = OrderedDict(chain.from_iterable(L))\\n>>> [[k, counter[k]] for k in order]\\n[['one', 1], ['two', 1], ['three', 2], ['four', 1], ['five', 1]]\\n\", 'attribution': 'https://stackoverflow.com/questions/33139499', 'language': 'python', 'rawDescription': 'python: fast and easy way to compare these lists?', 'id': '33139499_3'}\nPython: fast and easy way to compare these lists\nfoo = [['one', 1], ['two', 1], ['three', 1]]\nbar = [['three', 1], ['four', 1], ['five', 1]]\nfrom collections import Counter\nfrom collections import OrderedDict\nfrom itertools import chain\nL = [foo, bar]\ncounter = Counter()\nfor item in L:\n    counter.update(dict(item))\n\norder = OrderedDict(chain.from_iterable(L))\n[[k, counter[k]] for k in order]\n{'code': \">>> d = {1: 'Foo', 2: 'Bar', 3: 'Chazz', 4: 'Alpha', 6: 'Zorn', 7: 'Doe'}    \\n>>> sorted(d, key=d.get)\\n[4, 2, 3, 7, 1, 6]\\n\", 'attribution': 'https://stackoverflow.com/questions/28016639', 'language': 'python', 'rawDescription': 'dictionary keys sorted by value', 'id': '28016639_0'}\nDictionary keys sorted by value\nd = {1: 'Foo', 2: 'Bar', 3: 'Chazz', 4: 'Alpha', 6: 'Zorn', 7: 'Doe'}    \nsorted(d, key=d.get)\n{'code': '>>> photodict = json.loads(quoted_resp)\\n>>> for meta in photodict[\\'photo\\'][\\'exif\\']:                                                                                                               \\n...     if meta[\"tagspace\"] == \"GPS\" and meta[\"tag\"] == \"GPSLongitude\":\\n...         print(meta[\"clean\"][\"_content\"])\\n... \\n116 deg 16\\' 10.20\" E\\n', 'attribution': 'https://stackoverflow.com/questions/28521786', 'language': 'python', 'rawDescription': 'parse special json format with python', 'id': '28521786_3'}\nParse special json format with python\nphotodict = json.loads(quoted_resp)\nfor meta in photodict['photo']['exif']:                                                                                                               \n    if meta[\"tagspace\"] == \"GPS\" and meta[\"tag\"] == \"GPSLongitude\":\n        print(meta[\"clean\"][\"_content\"])\n\n{'code': '>>> s = \"The quick brown fox jumps over the lazy dog\"\\n>>> l = [1, 8, 14, 18, 27]\\n>>> l = [0] + l + [len(s)]\\n>>> [s[x:y] for x,y in zip(l, l[1:])]\\n[\\'T\\', \\'he quic\\', \\'k brow\\', \\'n fo\\', \\'x jumps o\\', \\'ver the lazy dog\\']\\n', 'attribution': 'https://stackoverflow.com/questions/35670229', 'language': 'python', 'rawDescription': \"What's the pythonic way to cut a string at multiple positions?\", 'id': '35670229_0'}\nWhat's the pythonic way to cut a string at multiple positions\ns = \"The quick brown fox jumps over the lazy dog\"\nl = [1, 8, 14, 18, 27]\nl = [0] + l + [len(s)]\n[s[x:y] for x,y in zip(l, l[1:])]\n"
    }
   ],
   "source": [
    "from codesearch.text_preprocessing import clean_how_to\n",
    "\n",
    "i = 0\n",
    "for s in raw_snippets:\n",
    "    code = s[\"code\"]\n",
    "    cleaned, cleaned_code = maybe_clean_prompt(code)\n",
    "    description = s[\"rawDescription\"]\n",
    "    cleaned_description = clean_how_to(description)\n",
    "    if cleaned and description != cleaned_description:\n",
    "        print(s)\n",
    "        print(cleaned_description)\n",
    "        print(cleaned_code)\n",
    "        i += 1\n",
    "    if i == 10: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesearch.data import load_jsonl\n",
    "staqc_raw = \"staqc-py-raw.jsonl\"\n",
    "raw_snippets = load_jsonl(staqc_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseable_py3, unparseable_py3 = split_parseable(raw_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(173011, 99318)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(parseable_py3), len(unparseable_py3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "staqc_py3_parseable = \"staqc-snippets-py3-parseable.jsonl\"\n",
    "staqc_py3_unparseable = \"staqc-snippets-py3-unparseable.jsonl\"\n",
    "\n",
    "with open(staqc_py3_parseable, \"w\") as f:\n",
    "    for r in parseable_py3:\n",
    "        r = json.dumps(r)\n",
    "        f.write(r)\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open(staqc_py3_unparseable, \"w\") as f:\n",
    "    for r in unparseable_py3:\n",
    "        r = json.dumps(r)\n",
    "        f.write(r)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(99318,\n [{u'attribution': u'https://stackoverflow.com/questions/19612419',\n   u'code': u\"def rotate(*args):\\n    print 'rotate button press...'\\n    theta = 90\\n    rotated = ndimage.rotate(image, theta)\\n    im.set_data(rotated)\\n    canvas.draw()\\n\",\n   u'id': u'19612419_0',\n   u'language': u'python',\n   u'rawDescription': u'updating matplotlib imshow from within a Tkinter gui'},\n  {u'attribution': u'https://stackoverflow.com/questions/34773625',\n   u'code': u'class Report(object):\\n  .\\n  .\\n  def new_hosts(self):\\n      \"\"\"Return a list of new hosts added in latest scan\"\"\"\\n      return self.curr_hosts - self.prev_hosts\\n',\n   u'id': u'34773625_0',\n   u'language': u'python',\n   u'rawDescription': u'How to print notification to slack by calling a function via python'}])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import json\n",
    "staqc_py3_unparseable = \"staqc-snippets-py3-unparseable.jsonl\"\n",
    "\n",
    "snippets = []\n",
    "with open(staqc_py3_unparseable, \"rb\") as f:\n",
    "    for l in f:\n",
    "        snippets.append(json.loads(l[:-1]))\n",
    "\n",
    "len(snippets), snippets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(30689, 68629)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "parseable_py2, unparseable = split_parseable(snippets)\n",
    "\n",
    "len(parseable_py2), len(unparseable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "staqc_py2_parseable = \"staqc-snippets-py2-parseable.jsonl\"\n",
    "\n",
    "with open(staqc_py2_parseable, \"wb\") as f:\n",
    "    for r in parseable_py2:\n",
    "        r = json.dumps(r)\n",
    "        f.write(r)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can use python3 again\n",
    "\n",
    "We will merge the parseable snippets and clean the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "203700"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from codesearch.data import load_jsonl\n",
    "staqc_py3_parseable = \"staqc-snippets-py3-parseable.jsonl\"\n",
    "staqc_py2_parseable = \"staqc-snippets-py2-parseable.jsonl\"\n",
    "\n",
    "snippets = load_jsonl(staqc_py3_parseable)\n",
    "snippets.extend(load_jsonl(staqc_py2_parseable))\n",
    "\n",
    "len(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesearch.text_preprocessing import clean_how_to\n",
    "import re\n",
    "\n",
    "how_to_pattern = \"^([hH]ow to |[hH]ow do ([Ii] |you )|[Hh]ow does one |([tT]he )?[Bb]est way to |([Hh]ow )?[Cc]an (you |[Ii] ))\"\n",
    "\n",
    "def clean_how_to(t):\n",
    "    t = re.sub(how_to_pattern, \"\", t)\n",
    "    if t.endswith(\"?\"):\n",
    "        t = t[:-1]\n",
    "    return t[0].capitalize() + t[1:]\n",
    "\n",
    "for s in snippets:\n",
    "    s[\"description\"] = clean_how_to(s[\"rawDescription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "How can I verify my selfsigned certificate when using easywebdav?\nVerify my selfsigned certificate when using easywebdav\n\nHow to break down a number with another from list?\nBreak down a number with another from list\n\nHow to do write a Python script that inputs all files from a certain subdirectory from command line?\nDo write a Python script that inputs all files from a certain subdirectory from command line\n\ntxredisapi subscribe and listen async\nTxredisapi subscribe and listen async\n\nhow to make regex go line by line to match two strings at the same time?\nMake regex go line by line to match two strings at the same time\n\nHow to reorder indexed rows based on a list in Pandas data frame\nReorder indexed rows based on a list in Pandas data frame\n\nWhat hash algorithm does Python's dictionary mapping use?\nWhat hash algorithm does Python's dictionary mapping use\n\npython list comprehension get dictionary by key\nPython list comprehension get dictionary by key\n\nHow to slice and extend a 2D numpy array?\nSlice and extend a 2D numpy array\n\nHow to convert nested dictionary into a 2D table\nConvert nested dictionary into a 2D table\n\n"
    }
   ],
   "source": [
    "i = 0\n",
    "for s in snippets:\n",
    "    \n",
    "    if s[\"description\"] != s[\"rawDescription\"]:\n",
    "        print(s[\"rawDescription\"])\n",
    "        print(s[\"description\"])\n",
    "        print()\n",
    "        i += 1\n",
    "        if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "staqc_cleaned = \"staqc-py-cleaned.jsonl\"\n",
    "\n",
    "with open(staqc_cleaned, \"w\") as f:\n",
    "    for r in snippets:\n",
    "        r = json.dumps(r)\n",
    "        f.write(r)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation datasets\n",
    "\n",
    "Next, we create evaluation datasets from stack overflow duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(195498,\n [{'original': ['73713',\n    \"How do I check for nulls in an '==' operator overload without infinite recursion?\"],\n   'duplicates': [['86947',\n     'Best way to handle null when writing equals operator'],\n    ['58388750',\n     \"How to compare two objects of different types where one inherits the other's type\"],\n    ['4219261', 'Overriding == operator. How to compare to null?'],\n    ['4867909',\n     \"When overloading the equality operator, what's the best way to handle null values?\"],\n    ['1042147', '(C#) Problems when overloading the == operator'],\n    ['14428218', 'How can i implement == and check for null in c#'],\n    ['9059085', 'C# equality operators override (== and !=)'],\n    ['39681387', 'Why Use Value Equality On a Reference Type'],\n    ['39877764',\n     'Overriding Equals/GetHashCode for class in order to use hashset Contains/ExceptWith/UnionWith'],\n    ['52767648', 'How can I ignore an operator overload'],\n    ['24762789', 'how to avoid stackoverflow in == overload'],\n    ['26775303', 'Operator overloading giving error'],\n    ['104158',\n     'What is \"Best Practice\" For Comparing Two Instances of a Reference Type?'],\n    ['24317508', 'C# operator == check for null'],\n    ['14011989', 'Having problems comparing two custom class objects']]},\n  {'original': ['85122',\n    'How to make thread sleep less than a millisecond on Windows'],\n   'duplicates': [['4128766', 'How accurate is Sleep() or sleep()'],\n    ['11063978', 'C++: How to sleep for a nanosecond?'],\n    ['9518106',\n     'WinAPI Sleep() function call sleeps for longer than expected'],\n    ['5766044', 'Sleeping for less than a millisecond in C++'],\n    ['4986818', 'How to sleep for a few microseconds'],\n    ['43057578',\n     'C programming, win32, games, Sleep() taking longer than expected']]}])"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "from codesearch.data import load_train_dataset\n",
    "\n",
    "duplicates = load_train_dataset(\"so-duplicates-feb20\")\n",
    "len(duplicates), duplicates[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(737274,\n [('86947', '73713'), ('58388750', '73713')],\n 195498,\n [('73713',\n   [['86947', 'Best way to handle null when writing equals operator'],\n    ['58388750',\n     \"How to compare two objects of different types where one inherits the other's type\"],\n    ['4219261', 'Overriding == operator. How to compare to null?'],\n    ['4867909',\n     \"When overloading the equality operator, what's the best way to handle null values?\"],\n    ['1042147', '(C#) Problems when overloading the == operator'],\n    ['14428218', 'How can i implement == and check for null in c#'],\n    ['9059085', 'C# equality operators override (== and !=)'],\n    ['39681387', 'Why Use Value Equality On a Reference Type'],\n    ['39877764',\n     'Overriding Equals/GetHashCode for class in order to use hashset Contains/ExceptWith/UnionWith'],\n    ['52767648', 'How can I ignore an operator overload'],\n    ['24762789', 'how to avoid stackoverflow in == overload'],\n    ['26775303', 'Operator overloading giving error'],\n    ['104158',\n     'What is \"Best Practice\" For Comparing Two Instances of a Reference Type?'],\n    ['24317508', 'C# operator == check for null'],\n    ['14011989', 'Having problems comparing two custom class objects']]),\n  ('85122',\n   [['4128766', 'How accurate is Sleep() or sleep()'],\n    ['11063978', 'C++: How to sleep for a nanosecond?'],\n    ['9518106',\n     'WinAPI Sleep() function call sleeps for longer than expected'],\n    ['5766044', 'Sleeping for less than a millisecond in C++'],\n    ['4986818', 'How to sleep for a few microseconds'],\n    ['43057578',\n     'C programming, win32, games, Sleep() taking longer than expected']])])"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "id2orig = {}\n",
    "orig2dupls = {}\n",
    "for r in duplicates:\n",
    "    orig_id = r[\"original\"][0]\n",
    "    ids = [t[0] for t in r[\"duplicates\"]]\n",
    "    orig2dupls[orig_id] = r[\"duplicates\"]\n",
    "    for id in ids:\n",
    "        id2orig[id] = orig_id\n",
    "    id2orig[orig_id] = orig_id\n",
    "\n",
    "len(id2orig), list(id2orig.items())[:2], len(orig2dupls), list(orig2dupls.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "128550"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "id2snippets = defaultdict(list)\n",
    "for s in snippets:\n",
    "    so_id = s[\"id\"].split(\"_\")[0]\n",
    "    id2snippets[so_id].append(s[\"id\"])\n",
    "len(id2snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10261,\n 6282,\n [['18126552', '19463598', '100003', '17801344'],\n  ['16881955'],\n  ['10012534', '16496733'],\n  ['10012788'],\n  ['1001538'],\n  ['1001634'],\n  ['10017086'],\n  ['10017147'],\n  ['36220375', '100210', '4557577', '4541629'],\n  ['10021749']])"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "ids_in_duplicates = [(id, id2orig[id]) for id in id2snippets if id in id2orig]\n",
    "ids_in_duplicates = sorted(ids_in_duplicates, key=itemgetter(1))\n",
    "groups = groupby(ids_in_duplicates, key=itemgetter(1))\n",
    "ids_by_duplicate_group = [[item[0] for item in data] for (key, data) in groups]\n",
    "len(ids_in_duplicates), len(ids_by_duplicate_group), ids_by_duplicate_group[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5497,\n 2748.5,\n [{'query': 'Django - Switch language setting for template rendering',\n   'relevant_ids': ['5258715']},\n  {'query': 'How to extract all fields minus a couple from a dictionary?',\n   'relevant_ids': ['8717395_1', '8717395_0']},\n  {'query': 'Extra backslash gets added when reading a path',\n   'relevant_ids': ['26903155_1', '26903155_0']},\n  {'query': 'How do you generate all possible permutations in python?',\n   'relevant_ids': ['11463237']},\n  {'query': 'Pandas Column names to list - correct method',\n   'relevant_ids': ['19482970']},\n  {'query': 'Python - connect to S3 with profile only?',\n   'relevant_ids': ['33378422_0', '33378422_1']},\n  {'query': 'How to mix asyncio code in with blocking code?',\n   'relevant_ids': ['28492103']},\n  {'query': 'How to calculated R2 and R2 adjusted via poly_fit numpy, pandas',\n   'relevant_ids': ['893657_1', '893657_0']},\n  {'query': 'Python sort using key and lambda, what does lambda do?',\n   'relevant_ids': ['26877806']},\n  {'query': 'Django: set the foreign key field of model which is related with User',\n   'relevant_ids': ['8466768_0']},\n  {'query': 'ABC ----> ABC, CAB, BCA only order matters but not truly a itertools permutation',\n   'relevant_ids': ['8458244_0', '8458244_1', '8458244_2', '8458244_3']},\n  {'query': 'How to convert csv to dictionary',\n   'relevant_ids': ['6207785', '5695395']},\n  {'query': 'Is there a python t test for difference?',\n   'relevant_ids': ['2324438']},\n  {'query': 'Pass several arguments to function from map()',\n   'relevant_ids': ['10834960_1', '10834960_0', '16066644_0', '16066644_1']},\n  {'query': 'how to get timezone-aware midnight datetime in python?',\n   'relevant_ids': ['34291963']},\n  {'query': 'Google App Engine unique=True?',\n   'relevant_ids': ['1185628_0', '1185628_1']},\n  {'query': 'All threads in my python application appear as \"python3\"',\n   'relevant_ids': ['34361035_0']},\n  {'query': \"python merging pairs lists within sublists within a list by comparing previous pair's second number with next pair's first number\",\n   'relevant_ids': ['5679638']},\n  {'query': 'Speed up applying a function to dataframe rows',\n   'relevant_ids': ['22084338_0', '22084338_2', '22084338_1']},\n  {'query': 'Sort nested list: Exclude first item from sorting',\n   'relevant_ids': ['5827592']},\n  {'query': 'Expecting input from std::cin (Unix C++)',\n   'relevant_ids': ['13669381']},\n  {'query': 'Deleting a name from a text file in Python',\n   'relevant_ids': ['32788380']},\n  {'query': 'Python: Write a subclass of \"property\" with special setting behavior',\n   'relevant_ids': ['12405087']},\n  {'query': 'How to close linux terminal with python script',\n   'relevant_ids': ['4214773', '34389322']},\n  {'query': 'Subprocesses finished but parent process hung up',\n   'relevant_ids': ['11854519']},\n  {'query': 'How to parse dict element from variable into a exist dict variable without extra variable?',\n   'relevant_ids': ['1551666_1',\n    '1551666_0',\n    '8930915_1',\n    '8930915_0',\n    '8930915_2',\n    '577234']},\n  {'query': \"How to made a read-only attribute with the python's property function when the class's attributes have setters functions too?\",\n   'relevant_ids': ['9920677']},\n  {'query': \"How to replace latest month's value with the previous month's value for all observations in time series data?\",\n   'relevant_ids': ['33261359_1', '33261359_0']},\n  {'query': 'Activate non-active sheet using openpyxl',\n   'relevant_ids': ['36814050_1', '36814050_0']},\n  {'query': 'Unique DB entry to the user',\n   'relevant_ids': ['2201598_0', '2201598_1']}])"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "eval_data = []\n",
    "\n",
    "\n",
    "for ids_duplicate_group in ids_by_duplicate_group:\n",
    "    orig_ids = set(id2orig[id] for id in ids_duplicate_group)\n",
    "    assert(len(orig_ids) == 1)\n",
    "    orig_id = orig_ids.pop()\n",
    "    all_duplicates = orig2dupls[orig_id]\n",
    "    query = None\n",
    "    for dupl_id, description in all_duplicates:\n",
    "        if dupl_id not in ids_duplicate_group:\n",
    "            query = description\n",
    "            break\n",
    "    if query:\n",
    "        relevant_ids = [ snippet_id for so_id in ids_duplicate_group for snippet_id in id2snippets[so_id]]\n",
    "        eval_record = {\"query\": query, \"relevant_ids\": relevant_ids}\n",
    "        eval_data.append(eval_record)\n",
    "\n",
    "\n",
    "random.seed(123)          \n",
    "random.shuffle(eval_data)\n",
    "len(eval_data), len(eval_data)/2, eval_data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check, should not print any id\n",
    "snippet_ids = set(s[\"id\"] for s in snippets)\n",
    "\n",
    "for r in eval_data:\n",
    "    for sid in r[\"relevant_ids\"]:\n",
    "        if sid not in snippet_ids:\n",
    "            print(sid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_raw = 'staqc-py-eval-raw.jsonl'\n",
    "\n",
    "with open(eval_data_raw, \"w\") as f:\n",
    "    for r in eval_data:\n",
    "        f.write(json.dumps(r))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = 'staqc-py-test-raw.jsonl'\n",
    "valid_data_raw = 'staqc-py-valid-raw.jsonl'\n",
    "\n",
    "!head -n 2749 $eval_data_raw > $test_data_raw\n",
    "!tail -n 2748 $eval_data_raw > $valid_data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Manually clean the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def display_query_snippet(idx, total, query, snippet):\n",
    "    descr = snippet[\"description\"].replace('\\n', '\\\\n')\n",
    "    code = snippet[\"code\"]\n",
    "    id = snippet[\"id\"]\n",
    "    mkdown = f\"{idx}/{total}<br>**query**: {query}\\n\\n**description**: {descr}\\n```python\\n{code}\\n\\n\\n\\n```\"\n",
    "    return Markdown(mkdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_eval_data(eval_data, queries_to_skip, shuffle=True):\n",
    "    for i, r in enumerate(eval_data):\n",
    "        if r[\"query\"] in queries_to_skip:\n",
    "            continue\n",
    "        relevant_ids = []\n",
    "        for relevant_id in r[\"relevant_ids\"]:\n",
    "            is_relevant = \"?\"\n",
    "            while is_relevant == \"?\":\n",
    "                clear_output(wait=True)\n",
    "                display(display_query_snippet(i + 1, len(eval_data), r[\"query\"], id2snippets[relevant_id]))\n",
    "                input_str = input(\"relevant y/n: \")\n",
    "                if input_str in [\"y\", \"Y\", \"1\"]:\n",
    "                    is_relevant = True\n",
    "                elif input_str in [\"n\", \"N\", \"0\"]:\n",
    "                    is_relevant = False\n",
    "                elif input_str in [\"q\", \"Q\"]:\n",
    "                    return\n",
    "                else:\n",
    "                    is_relevant = \"?\"\n",
    "            if is_relevant:\n",
    "                relevant_ids.append(relevant_id)\n",
    "        if relevant_ids:\n",
    "            record = dict(r)\n",
    "            record[\"relevant_ids\"] = relevant_ids\n",
    "            yield record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from codesearch.data import load_jsonl\n",
    "\n",
    "test_data_raw_ = load_jsonl(test_data_raw)\n",
    "test_data_filtered = 'staqc-py-test-cleaned.jsonl'\n",
    "if Path(test_data_filtered).exists():\n",
    "    overwrite = input(f\"{test_data_filtered} already exist, do you want to overwrite the file y/n:\")\n",
    "    if overwrite not in [\"y\", \"Y\"]:\n",
    "        records = load_jsonl(test_data_filtered)\n",
    "        queries = set(r[\"query\"] for r in records)\n",
    "    else:\n",
    "        queries = set()\n",
    "        os.remove(test_data_filtered)\n",
    "    \n",
    "with open(test_data_filtered, \"a\") as f:\n",
    "    for r in filter_eval_data(test_data_raw_, queries):\n",
    "        f.write(json.dumps(r))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "How much space does my python program use?\n['Total memory used by Python process', 'Total memory used by Python process']\nimport os\n_proc_status = '/proc/%d/status' % os.getpid()\n\n_scale = {'kB': 1024.0, 'mB': 1024.0*1024.0,\n          'KB': 1024.0, 'MB': 1024.0*1024.0}\n\ndef _VmB(VmKey):\n    '''Private.\n    '''\n    global _proc_status, _scale\n     # get pseudo file  /proc/<pid>/status\n    try:\n        t = open(_proc_status)\n        v = t.read()\n        t.close()\n    except:\n        return 0.0  # non-Linux?\n     # get VmKey line e.g. 'VmRSS:  9999  kB\\n ...'\n    i = v.index(VmKey)\n    v = v[i:].split(None, 3)  # whitespace\n    if len(v) < 3:\n        return 0.0  # invalid format?\n     # convert Vm value to bytes\n    return float(v[1]) * _scale[v[2]]\n\n\ndef memory(since=0.0):\n    '''Return memory usage in bytes.\n    '''\n    return _VmB('VmSize:') - since\n\n\ndef resident(since=0.0):\n    '''Return resident memory usage in bytes.\n    '''\n    return _VmB('VmRSS:') - since\n\n\ndef stacksize(since=0.0):\n    '''Return stack size in bytes.\n    '''\n    return _VmB('VmStk:') - since\n\n"
    }
   ],
   "source": [
    "from codesearch.data import load_eval_dataset, load_snippet_collection\n",
    "\n",
    "id2snippet = {r[\"id\"]:r for r in load_snippet_collection(\"staqc-py-cleaned\")}\n",
    "_, query2id = load_eval_dataset(\"staqc-py-raw-valid\")\n",
    "i = 0\n",
    "for q in query2id:\n",
    "    if q != \"How much space does my python program use?\": continue\n",
    "    ids = query2id[q]\n",
    "    print(q)\n",
    "    print([id2snippet[id][\"description\"] for id in ids])\n",
    "    print([id2snippet[id][\"code\"] for id in ids][0])\n",
    "\n",
    "    i += 1\n",
    "    if i == 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}