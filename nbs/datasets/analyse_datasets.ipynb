{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597053164830",
   "display_name": "Python 3.7.7 64-bit ('codesearch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© 2020 Nokia\n",
    "\n",
    "Licensed under the BSD 3 Clause license\n",
    "\n",
    "SPDX-License-Identifier: BSD-3-Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (\"CoNaLa\", \"conala-curated\", None, \"conala-curated-0.5-test\"),\n",
    "    (\"StaQC-py\", \"staqc-py-cleaned\", \"staqc-py-raw-valid\", \"staqc-py-raw-test\"),\n",
    "    (\"SO-DS\", \"so-ds-feb20\", \"so-ds-feb20-valid\", \"so-ds-feb20-test\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute overlap between queries and snippet descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesearch.data import load_eval_dataset, load_snippet_collection\n",
    "from codesearch.text_preprocessing import compute_overlap\n",
    "\n",
    "def queries_and_descriptions(snippet_collection, eval_dataset):\n",
    "    _, query2ids = load_eval_dataset(eval_dataset)\n",
    "    snippets = load_snippet_collection(snippet_collection)\n",
    "    id2snippet = {s[\"id\"]: s for s in snippets}\n",
    "    qs_and_ds = []\n",
    "    for q in query2ids:\n",
    "        descriptions = [id2snippet[id][\"description\"] for id in query2ids[q]]\n",
    "        qs_and_ds.append((q, descriptions))\n",
    "\n",
    "    return qs_and_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CoNaLa conala-curated conala-curated-0.5-test\n0.27871314136946373\nStaQC-py staqc-py-cleaned staqc-py-raw-test\n0.2851193095778236\nSO-DS so-ds-feb20 so-ds-feb20-test\n0.27731259865052305\n"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_overlaps(query_rel_overlaps, dataset):\n",
    "    plt.hist(query_rel_overlaps, bins=np.arange(0, 1.1, 0.1))\n",
    "    plt.title(dataset)\n",
    "    plt.xlabel('word overlap (query vs matching snippet description)', fontsize=12)\n",
    "    plt.ylabel('# queries', fontsize=12)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=11)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=11)\n",
    "    mean = np.array(query_rel_overlaps).mean()\n",
    "    print(mean)\n",
    "    plt.axvline(mean, color='red', linewidth=2)\n",
    "    plt.annotate('mean = {:0.2f}'.format(mean), xy=(mean + 0.05, .95), xycoords=('data', 'axes fraction'), color='red') #, xytext=(xoff, 15)\n",
    "\n",
    "\n",
    "    plt.savefig(f'/Users/heyman/Documents/code-search-paper/figures/query_rel_overlap_{dataset}.pdf')\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "for name, snippet_collection, _, test_dataset in datasets:\n",
    "    overlaps = []\n",
    "    print(name, snippet_collection, test_dataset)\n",
    "    for q, descriptions in queries_and_descriptions(snippet_collection, test_dataset):\n",
    "        _, overlap = max(compute_overlap(q, d) for d in descriptions)\n",
    "        overlaps.append(overlap)\n",
    "    plot_overlaps(overlaps, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- snippet collection:\n",
    "    - size (\\# snippets)\n",
    "    - description length (\\# tokens)\n",
    "    - snippet length (\\# LOC)\n",
    "- ground truth valid\n",
    "    - size (\\# queries)\n",
    "    - \\# matching snippets per query\n",
    "- ground truth test\n",
    "    - size (\\# queries)\n",
    "    - \\# matching snippets per query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CoNaLa\n2777.00 & 10.32 & 1.07 & nan & nan & 762.00 & 1.17\nStaQC-py\n203700.00 & 8.36 & 9.84 & 2599.00 & 2.01 & 2749.00 & 3.40\nSO-DS\n12137.00 & 7.35 & 14.98 & 947.00 & 1.69 & 1113.00 & 1.70\n"
    }
   ],
   "source": [
    "\n",
    "def description_len(snippets):\n",
    "    len_sum = 0\n",
    "    for s in snippets:\n",
    "        len_sum += len(s[\"description\"].strip().split())\n",
    "    return len_sum/len(snippets)\n",
    "\n",
    "def snippet_len(snippets):\n",
    "    len_sum = 0\n",
    "    for s in snippets:\n",
    "        len_sum += len(s[\"code\"].split(\"\\n\"))\n",
    "    return len_sum/len(snippets)\n",
    "\n",
    "def summarize_snippet_collection(snippet_collection):\n",
    "    snippets = load_snippet_collection(snippet_collection)\n",
    "    size = len(snippets)\n",
    "    description_length = description_len(snippets)\n",
    "    snippet_length = snippet_len(snippets)\n",
    "    return size, description_length, snippet_length\n",
    "\n",
    "def summarize_eval_dataset(eval_dataset):\n",
    "    if not eval_dataset:\n",
    "        return np.nan, np.nan\n",
    "    _, query2id = load_eval_dataset(eval_dataset)\n",
    "    size = len(query2id)\n",
    "    num_matching = sum(len(ids) for ids in query2id.values())\n",
    "    return size, num_matching/size\n",
    "\n",
    "for name, snippet_collection, valid_dataset, test_dataset in datasets:\n",
    "    snippet_summary = summarize_snippet_collection(snippet_collection)\n",
    "    valid_summary = summarize_eval_dataset(valid_dataset)\n",
    "    test_summary = summarize_eval_dataset(test_dataset)\n",
    "    print(name)\n",
    "    print(' & '.join([ '{:0.2f}'.format(x) for x in (snippet_summary + valid_summary + test_summary)]))\n",
    "\n"
   ]
  }
 ]
}